<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<!-- saved from url=(0037)http://bcmi.sjtu.edu.cn/home/zhangzs/ -->
<html xml:lang="en" xmlns="http://www.w3.org/1999/xhtml" class="gr__bcmi_sjtu_edu_cn"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<meta content="IE=7.0000" http-equiv="X-UA-Compatible">
<title>Zhuosheng Zhang, Shanghai Jiao Tong University</title>
<meta name="keywords" content="Zhuosheng Zhang,Shanghai Jiao Tong University">
<link rel="stylesheet" type="text/css" href="./Zhuosheng Zhang, Shanghai Jiao Tong University_files/jemdoc.css"><link rel="shortcut icon" href="http://bcmi.sjtu.edu.cn/home/zhangzs/rui.ico">

<link href="./Zhuosheng Zhang, Shanghai Jiao Tong University_files/font-awesome.min.css" rel="stylesheet">
                        
<meta name="GENERATOR" content="MSHTML 11.00.9600.17280"></head>
<body style="font-family:Helvetica Neue, Helvetica, Arial, sans-serif;" data-gr-c-s-loaded="true">
<div id="layout-content">
<p>
<script type="text/javascript">
<!--
// Toggle Display of BibTeX
function toggleBibtex(articleid) {
  var bib = document.getElementById(articleid);
  // Toggle 
    if(bib.style.display == "none") {
      bib.style.display = "";
    }
    else {
      bib.style.display = "none";
    }
}
</script>

</p>
<p></p>
<table class="imgtable">
  <tbody>
  <tr>
    <td><img alt="Zhuosheng Zhang" height="160px" width="160px" src="./Zhuosheng Zhang, Shanghai Jiao Tong University_files/photo6.jpg"> &nbsp;&nbsp;&nbsp;</td>
    <td align="left">
      <div id="toptitle">
      <h1>Zhuosheng Zhang
      </h1></div>
      <p> Computer Science <br> Shanghai Jiao Tong University  
      <br>Email: zhangzs AT sjtu DOT edu DOT cn
      <br>Office: Room 220, SEIEE Building #3
      <br>Github: <a href="https://github.com/cooelf">https://github.com/cooelf</a>
      </p></td></tr></tbody>
</table>

<table class="imgtable">
<tbody><tr>

<td>
<span style="color:blue;">
<a href="http://bcmi.sjtu.edu.cn/home/zhangzs/#Publications"><u>Publications</u></a>
</span>&nbsp;&nbsp;&nbsp;&nbsp;
<span style="color:blue;">
<a href="http://bcmi.sjtu.edu.cn/home/zhangzs/#Shared">
<span>
  <u>Shared Tasks</u>
</span></a>
&nbsp;&nbsp;&nbsp;&nbsp;
<a href="http://bcmi.sjtu.edu.cn/home/zhangzs/#AWARDS"><u>Awards</u></a>
</span>

</td>
</tr>
</tbody></table>

<h2>Profile</h2>
    <p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Hi! I am a master student in the <a href="http://www.cs.sjtu.edu.cn/"> Department of Computer Science and Engineering </a> at <a href="http://www.sjtu.edu.cn/"> Shanghai Jiao Tong University</a> (expected to graduate in 2020). I am advised by <a href="http://bcmi.sjtu.edu.cn/~zhaohai/">Prof. Hai Zhao</a> and work in the <a href="http://bcmi.sjtu.edu.cn/">BCMI-NLP Group</a>. <br>
</p>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;My main research interests lie within deep learning for natural language processing and understanding, and I am particularly interested in <b>question answering</b> and <b>machine reading comprehension</b>.


<h2>Education</h2>

<!-- 2 -->
<ul>
  <li>
       2016.9-Present: Master student at Shanghai Jiao Tong University
  </li>
  
    <li>
       2012.9-2016.6: B.Eng student at Wuhan University
  </li>
  
</ul>

<!--
<H2>NEWS <img src="pubs/new_gif_1.gif"></H2>
<UL>
  <LI>
  <P> Three full papers have been accepted by <a href="http://coling2018.org/"> COLING 2018 </a>. 
 </UL>
-->

<!--
<H2>EDUCATION</H2>


<UL>
  <LI>
       2016.9-Present: Master student at Shanghai Jiao Tong University
  </LI>
  
    <LI>
       2012.9-2016.6: B.Eng student at Wuhan University (Rank 1/365)
  </LI>
  
</UL>
-->

<h2 id="Publications">Publications <a href="https://scholar.google.com/citations?user=63LTQhgAAAAJ" title="Google Scholar"><i class="fa fa-google"></i></a></h2>
<b>[2019]</b>

<ul>
    <li>
      <b>Zhuosheng Zhang</b>, Yafang Huang, Hai Zhao <br><i> Open Vocabulary Learning for Neural Chinese Pinyin IME</i>, The 57th Annual Meeting of the Association for Computational Linguistics (<b>ACL 2019</b>), Florence, Italy, July 28th to August 2nd, 2019.
      <br>[<a href="https://arxiv.org/pdf/1811.04352.pdf">PDF</a>]
      [<a href="javascript:toggleBibtex(&#39;IME_vocab_short&#39;)" target="_self">Abstract</a>]
      [<a href="javascript:toggleBibtex(&#39;acl2019ime_bib&#39;)" target="_self">Bib</a>] 
      [<a href="http://bcmi.sjtu.edu.cn/home/zhangzs/#">Link</a>]
      [<a href="https://github.com/cooelf/OpenIME">Source</a>]
        <div id="IME_vocab_short" class="blockcontent" style="DISPLAY: none">
            <table class="imgtable">
                <tbody>
                    <tr>
                        <td>
                            <p style="FONT-SIZE: 16px">
                               	Pinyin-to-character (P2C) conversion is the core component of pinyin-based Chinese input method engine (IME). However, the conversion is seriously compromised by the ambiguities of Chinese characters corresponding to pinyin as well as the predefined fixed vocabularies. To alleviate such inconveniences, we propose a neural P2C conversion model augmented by a large online updating vocabulary with a target vocabulary sampling mechanism to support an open vocabulary learning during IME working. Our experiments show that the proposed approach reduces the decoding time on CPUs up to 50$\%$ on P2C tasks at the same or only negligible change in conversion accuracy, and the online updated vocabulary indeed helps our IME effectively follows user inputting behavior.
                            </p>
                        </td>
                    </tr>
                </tbody>
            </table>
        </div>
          
        <div id="acl2019ime_bib" class="blockcontent" style="DISPLAY: none">
            <pre>@inproceedings{zhang2019acl,
	title = "{Open Vocabulary Learning for Neural Chinese Pinyin IME}",
	author = "Zhang, Zhuosheng and Huang, Yafang and Zhao, Hai",
	booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics (ACL)",
	year = "2019",
}
              </pre>
       </div>
    </li>
</ul>

<ul>
    <li>
      <b>Zhuosheng Zhang</b>, Hai Zhao, Kangwei Ling, Jiangtong Li, Zuchao Li, Shexia He. <br><i> Effective Subword Segmentation for Text Comprehension</i>, IEEE/ACM Transactions on Audio, Speech, and Language Processing (<b>TASLP</b>).
      <br>[<a href="http://bcmi.sjtu.edu.cn/home/zhangzs/#">PDF</a>]
      [<a href="javascript:toggleBibtex(&#39;subword_abstract&#39;)" target="_self">Abstract</a>]
      [<a href="http://bcmi.sjtu.edu.cn/home/zhangzs/#" target="_self">Bib</a>] 
      [<a href="http://bcmi.sjtu.edu.cn/home/zhangzs/#">Link</a>]
      [<a href="https://github.com/cooelf/subword_seg">Source</a>]
      <div id="subword_abstract" class="blockcontent" style="DISPLAY: none">
            <table class="imgtable">
                <tbody>
                    <tr>
                        <td>
                            <p style="FONT-SIZE: 16px">
                               	Representation learning is the foundation of machine reading comprehension and inference. In state-of-the-art models, character-level representations have been broadly adopted to alleviate the problem of effectively representing rare or complex words. However, character itself is not a natural minimal linguistic unit for representation or word embedding composing due to ignoring the linguistic coherence of consecutive characters inside word. This paper presents a general subword-augmented embedding framework for learning and composing computationally-derived subword-level representations. We survey a series of unsupervised segmentation methods for subword acquisition and different subword-augmented strategies for text understanding, showing that subword-augmented embedding significantly improves our baselines in various types of text understanding tasks on both English and Chinese benchmarks.
                            </p>
                        </td>
                    </tr>
                </tbody>
            </table>
        </div>
    </li>
</ul>

 <ul> 
   <li> Zuchao Li, Shexia He, Hai Zhao, Yiqing Zhang, <b>Zhuosheng Zhang</b>, Xi Zhou, Xiang Zhou. <br><i> Dependency or Span, End-to-End Uniform Semantic Role Labeling</i>, Proceedings of The Thirty-Third AAAI Conference on Artificial Intelligence (<b>AAAI-19</b>), January 27 - February 1, 2019, Honolulu, Hawaii, USA. <br>[<a href="http://bcmi.sjtu.edu.cn/~zhaohai/pubs/aaai2019-UniSRL-1113-2.pdf">PDF</a>] [<a href="javascript:toggleBibtex(&#39;srl_aaai19_abstract&#39;)" target="_self">Abstract</a>] [<a href="http://bcmi.sjtu.edu.cn/home/zhangzs/#" target="_self">Bib</a>] [<a href="https://aaai.org/Conferences/AAAI-19/">Link</a>] [<a href="https://github.com/bcmi220/unisrl">Source</a>] 
    <div id="srl_aaai19_abstract" class="blockcontent" style="DISPLAY: none"> 
     <table class="imgtable"> 
      <tbody> 
       <tr> 
        <td> <img alt="alt text" src="./Zhuosheng Zhang, Shanghai Jiao Tong University_files/srl_aaai19.png" width="400"> </td> 
        <td> <p style="FONT-SIZE: 16px"> Semantic role labeling (SRL) aims to discover the predicate-argument structure of a sentence. End-to-end SRL withoutsyntactic input has received great attention. However, mostof them focus on either span-based or dependency-based semantic representation form and only show specific model optimization respectively. Meanwhile, handling these two SRL tasks uniformly was less successful. This paper presents an end-to-end model for both dependency and span SRL with a unified argument representation to deal with two different types of argument annotations in a uniform fashion. Furthermore, we jointly predict all predicates and arguments,especially including long-term ignored predicate identification subtask. Our single model achieves new state-of-the-artresults on both span (CoNLL 2005, 2012) and dependency(CoNLL 2008, 2009) SRL benchmarks. </p> </td> 
       </tr> 
      </tbody> 
     </table> 
    </div> </li>
  </ul>



<b>[2018]</b>

<ul>
    <li>
      <b>Zhuosheng Zhang</b>, Jiangtong Li, Pengfei Zhu, Hai Zhao and Gongshen Liu. <br><i> Modeling Multi-turn Conversation with Deep Utterance Aggregation</i>, Proceedings of the 27th International Conference on Computational Linguistics (<b>COLING 2018</b>), pp.3740–3752, August 20-26, 2018, Santa Fe, New Mexico, USA.
      <br>[<a href="http://bcmi.sjtu.edu.cn/home/zhangzs/pubs/coling2018-dlg.pdf">PDF</a>]
      [<a href="javascript:toggleBibtex(&#39;dua_abstract&#39;)" target="_self">Abstract</a>]
      [<a href="javascript:toggleBibtex(&#39;dua_bib&#39;)" target="_self">Bib</a>] 
      [<a href="http://coling2018.org/">Link</a>]
      [<a href="https://github.com/cooelf/DeepUtteranceAggregation">Source</a>]
        <div id="dua_abstract" class="blockcontent" style="DISPLAY: none">
            <table class="imgtable">
                <tbody>
                    <tr>
                        <td>
                                <img alt="alt text" src="./Zhuosheng Zhang, Shanghai Jiao Tong University_files/dua.png" width="400">
                        </td>
                        <td>
                            <p style="FONT-SIZE: 16px">
                               Multi-turn conversation understanding is a major challenge for building intelligent dialogue systems. This work focuses on retrieval-based response matching for multi-turn conversation whose related work simply concatenates the conversation utterances, ignoring the interactions among previous utterances for context modeling. In this paper, we formulate previous utterances into context using a proposed deep utterance aggregation model to form a fine-grained context representation. In detail, a self-matching attention is first introduced to route the vital information in each utterance. Then the model matches a response with each refined utterance and the final matching score is obtained after attentive turns aggregation. Experimental results show our model outperforms the state-of-the-art methods on three multi-turn conversation benchmarks, including a newly introduced e-commerce dialogue corpus.
                            </p>
                        </td>
                    </tr>
                </tbody>
            </table>
        </div>
          
          <div id="dua_bib" class="blockcontent" style="DISPLAY: none">
            <pre>@inproceedings{zhang2018dua,
                title = {Modeling Multi-turn Conversation with Deep Utterance Aggregation},
                author = {Zhang, Zhuosheng and Li, Jiangtong and Zhu, Pengfei and Zhao, Hai},
                booktitle = {Proceedings of the 27th International Conference on Computational Linguistics (COLING 2018)},
                pages= {3740–-3752},
                year = {2018},
            }
              </pre>
          </div>
    </li>
</ul>

<ul>
    <li>
      <b>Zhuosheng Zhang</b>, Yafang Huang and Hai Zhao. <br><i> Subword-augmented Embedding for Cloze Reading Comprehension</i>, Proceedings of the 27th International Conference on Computational Linguistics (<b>COLING 2018</b>), pp.1802–1814, August 20-26, 2018, Santa Fe, New Mexico, USA.
      <br>[<a href="http://bcmi.sjtu.edu.cn/home/zhangzs/pubs/coling2018-mrc.pdf">PDF</a>]
      [<a href="javascript:toggleBibtex(&#39;mrc_abstract&#39;)" target="_self">Abstract</a>] 
      [<a href="javascript:toggleBibtex(&#39;mrc_bib&#39;)" target="_self">Bib</a>] 
      [<a href="http://coling2018.org/">Link</a>]
      [<a href="https://github.com/cooelf/subMrc">Source</a>]
        <div id="mrc_abstract" class="blockcontent" style="DISPLAY: none">
            <table class="imgtable">
                <tbody>
                    <tr>
                        <td>
                                <img alt="alt text" src="./Zhuosheng Zhang, Shanghai Jiao Tong University_files/mrc.png" width="400">
                        </td>
                        <td>
                            <p style="FONT-SIZE: 16px">
                               Representation learning is the foundation of machine reading comprehension. In state-of-the-art models, deep learning methods broadly use word and character level representations. However, character is not naturally the minimal linguistic unit. In addition, with a simple concatenation of character and word embedding, previous models actually give suboptimal solution. In this paper, we propose to use subword rather than character for word embedding enhancement. We also empirically explore different augmentation strategies on subword-augmented embedding to enhance the cloze-style reading comprehension model reader. In detail, we present a reader that uses subword-level representation to augment word embedding with a short list to handle rare words effectively. A thorough examination is conducted to evaluate the comprehensive performance and generalization ability of the proposed reader. Experimental results show that the proposed approach helps the reader significantly outperform the state-of-the-art baselines on various public datasets.
                            </p>
                        </td>
                    </tr>
                </tbody>
            </table>
        </div>
          
          <div id="mrc_bib" class="blockcontent" style="DISPLAY: none">
            <pre>@inproceedings{zhang2018mrc,
                title = {Subword-augmented Embedding for Cloze Reading Comprehension},
                author = {Zhang, Zhuosheng and Huang,Yafang and Zhao, Hai},
                booktitle = {Proceedings of the 27th International Conference on Computational Linguistics (COLING 2018)},
                pages = {1802-–1814},
                year = {2018},
            }
              </pre>
          </div>
    </li>
</ul>

<ul>
    <li>
      <b>Zhuosheng Zhang</b> and Hai Zhao. <br><i> One-shot Learning for Question-Answering in Gaokao History Challenge</i>, Proceedings of the 27th International Conference on Computational Linguistics (<b>COLING 2018</b>), pp.449–461, August 20-26, 2018, Santa Fe, New Mexico, USA.
      <br>[<a href="http://bcmi.sjtu.edu.cn/home/zhangzs/pubs/coling2018_qa.pdf">PDF</a>]
      [<a href="javascript:toggleBibtex(&#39;gaokao_abstract&#39;)" target="_self">Abstract</a>] 
      [<a href="javascript:toggleBibtex(&#39;gaokao_bib&#39;)" target="_self">Bib</a>] 
      [<a href="http://coling2018.org/">Link</a>]
      [<a href="https://github.com/cooelf/OneshotQA">Source</a>]
           <div id="gaokao_abstract" class="blockcontent" style="DISPLAY: none">
            <table class="imgtable">
                <tbody>
                    <tr>
                        <td>
                                <img alt="alt text" src="./Zhuosheng Zhang, Shanghai Jiao Tong University_files/gaokao.png" width="400">
                        </td>
                        <td>
                            <p style="FONT-SIZE: 16px">
                                Answering questions from university admission exams (Gaokao in Chinese) is a challenging AI task since it requires effective representation to capture complicated semantic relations between questions and answers. In this work, we propose a hybrid neural model for deep question-answering task from history examinations. Our model employs a cooperative gated neural network to retrieve answers with the assistance of extra labels given by a neural turing machine labeler. Empirical study shows that the labeler works well with only a small training dataset and the gated mechanism is good at fetching the semantic representation of lengthy answers. Experiments on question answering demonstrate the proposed model obtains substantial performance gains over various neural model baselines in terms of multiple evaluation metrics.
                            </p>
                        </td>
                    </tr>
                </tbody>
            </table>
        </div>
          
          <div id="gaokao_bib" class="blockcontent" style="DISPLAY: none">
            <pre>@inproceedings{zhang2018gaokao,
                title = {One-shot Learning for Question-Answering in Gaokao History Challenge},
                author = {Zhang, Zhuosheng and Zhao, Hai},
                booktitle = {Proceedings of the 27th International Conference on Computational Linguistics (COLING 2018)},
                pages = {449–-461},
                year = {2018},
            }
              </pre>
          </div>
    </li>
</ul>


<ul>
    <li>
      <b>Zhuosheng Zhang</b>, Yafang Huang, Pengfei Zhu, Hai Zhao. <br><i> Effective Character-augmented Word Embedding for Machine Reading Comprehension</i>, Proceedings of the Seventh CCF International Conference on Natural Language Processing and Chinese Computing (<b>NLPCC 2018</b>), pp.27-39, August 26-30, 2018, Hohhot, China.
      <br>[<a href="http://bcmi.sjtu.edu.cn/home/zhangzs/pubs/nlpcc_char.pdf">PDF</a>]
      [<a href="javascript:toggleBibtex(&#39;char_abstract&#39;)" target="_self">Abstract</a>]
      [<a href="javascript:toggleBibtex(&#39;char_bib&#39;)" target="_self">Bib</a>] 
      [<a href="http://tcci.ccf.org.cn/conference/2018/index.php">Link</a>]
        <div id="char_abstract" class="blockcontent" style="DISPLAY: none">
            <table class="imgtable">
                <tbody>
                    <tr>
                        <td>
                                <img alt="alt text" src="./Zhuosheng Zhang, Shanghai Jiao Tong University_files/nlpcc_char.png" width="400">
                        </td>
                        <td>
                            <p style="FONT-SIZE: 16px">
                               Machine reading comprehension is a task to model relationship between passage and query. In terms of deep learning framework, most of state-of-the-art models simply concatenate word and character level representations, which has been shown suboptimal for the concerned task. In this paper, we empirically explore different integration strategies of word and character embeddings and propose a character-augmented reader which attends character-level representation to augment word embedding with a short list to improve word representations, especially for rare words. Experimental results show that the proposed approach helps the baseline model significantly outperform state-of-the-art baselines on various public benchmarks. 
                        </p></td>
                    </tr>
                </tbody>
            </table>
        </div>
          
          <div id="char_bib" class="blockcontent" style="DISPLAY: none">
            <pre>@inproceedings{zhang2018char,
                title = {Effective Character-augmented Word Embedding for Machine Reading Comprehension},
                author = {Zhang, Zhuosheng and Huang, Yafang and Zhu, Pengfei and Zhao, Hai},
                booktitle = {Proceedings of the Seventh CCF International Conference on Natural Language Processing and Chinese Computing (NLPCC 2018)},
                pages = {27-39},
                year = {2018},
            }
              </pre>
          </div>
    </li>
</ul>


<ul>
    <li>
      Yafang Huang, Zuchao Li, <b>Zhuosheng Zhang</b>, Hai Zhao. <br><i> Neural-based Chinese Pinyin Aided Input Method with Customizable Association</i>, Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (<b>ACL 2018</b>), System Demonstration, pp.140–145, Melbourne, Australia, July 15-20, 2018.
      <br>[<a href="http://bcmi.sjtu.edu.cn/home/zhangzs/pubs/acl2018_demo_ime_camera.pdf">PDF</a>]
      [<a href="javascript:toggleBibtex(&#39;ime_abstract&#39;)" target="_self">Abstract</a>] 
      [<a href="javascript:toggleBibtex(&#39;ime_bib&#39;)" target="_self">Bib</a>] 
      [<a href="https://acl2018.org/">Link</a>]
      [<a href="http://ime.leisure-x.com/">Demo</a>] 
          <div id="ime_abstract" class="blockcontent" style="DISPLAY: none">
              <table class="imgtable">
                  <tbody>
                      <tr>
                        <td>
                                <img alt="alt text" src="./Zhuosheng Zhang, Shanghai Jiao Tong University_files/ime.png" width="400">
                        </td>
                        
                          <td>
                              <p style="FONT-SIZE: 16px">
                                   Chinese   pinyin   input   method   engine(IME)  lets  user  conveniently  input  Chinese  into  a  computer  by  typing  pinyin through  the  common  keyboard.   In  addition  to  offering  high  conversion  quality, modern pinyin IME is supposed to aid user  input  with  extended  association  function.  However, existing solutions for such functions  are  roughly  based  on  oversimplified matching algorithms at word-level, whose  resulting  products  provide  limited  extension  associated  with  user  inputs.   This  work  presents  the  Moon  IME,  a pinyin  IME  that  integrates  the  attention-based  neural  machine  translation  (NMT) model  and  Information  Retrieval  (IR)  to offer  amusive  and  customizable  association  ability. The  released  IME  is  implemented  on  Windows  via  text  services framework.
                              </p>
                          </td>
                      </tr>
                  </tbody>
              </table>
          </div>
          
          <div id="ime_bib" class="blockcontent" style="DISPLAY: none">
            <pre>@inproceedings{Huang2018Moon,
                    title={{Moon IME:} Neural-based Chinese Pinyin Aided Input Method with Customizable Association},
                    author={Huang,Yafang and Li,Zuchao and Zhang,Zhuosheng and Zhao,Hai},
                    booktitle={Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (ACL 2018), System Demonstrations},
                    pages = {140–145},
                    year={2018}
                }
              </pre>
          </div>
    </li>
</ul>

<ul>
    <li>
      Zuchao Li, Shexia He, Jiaxun Cai, <b>Zhuosheng Zhang</b> and Hai Zhao, Gongshen Liu, Linlin Li, Luo Si. <br><i> A Unified Syntax-aware Framework for Semantic Role Labeling</i>, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (<b>EMNLP 2018</b>), October 31 - November 4, 2018, Brussels, Belgium.
      <!--<br>[<a href="pubs/coling2018-dlg.pdf">PDF</a>]
       [<a href="javascript:toggleBibtex('dua_abstract')" target=_self>Abstract</a>]
      [<a href="javascript:toggleBibtex('dua_bib')" target=_self>Bib</a>] 
      [<a href="http://coling2018.org/"  >Link</a>]
      [<a href="https://github.com/cooelf/DeepUtteranceAggregation">Source</a>] -->
        <div id="srl_abstract" class="blockcontent" style="DISPLAY: none">
            <table class="imgtable">
                <tbody>
                    <tr>
                        <td>
                                <img alt="alt text" src="./Zhuosheng Zhang, Shanghai Jiao Tong University_files/dua.png" width="400">
                        </td>
                        <td>
                            <p style="FONT-SIZE: 16px">
                              
                            </p>
                        </td>
                    </tr>
                </tbody>
            </table>
        </div>
          
          <div id="srl_bib" class="blockcontent" style="DISPLAY: none">
            <pre>
              </pre>
          </div>
    </li>
</ul>

<ul>
  <li>
  <b>Zhuosheng Zhang</b>, Jiangtong Li, Hai Zhao, Bingjie Tang. <br><i> Neural Hypernym Discovery with Term Embeddings</i>, Proceedings of the 12th International Workshop on Semantic Evaluation (<b>SemEval 2018</b>), pp.903–908, Workshop of NAACL-HLT 2018, New Orleans, Louisiana, USA, June 1-6, 2018
  <br>[<a href="https://arxiv.org/pdf/1805.10465.pdf">PDF</a>]
  [<a href="javascript:toggleBibtex(&#39;NHD_abstract&#39;)" target="_self">Abstract</a>] 
  [<a href="javascript:toggleBibtex(&#39;NHD_bib&#39;)" target="_self">Bib</a>] 
  [<a href="http://alt.qcri.org/semeval2018/">Link</a>]
      <div id="NHD_abstract" class="blockcontent" style="DISPLAY: none">
          <table class="imgtable">
              <tbody>
                  <tr>
                      <td>
                          <p style="FONT-SIZE: 16px">
                              This paper describes a hypernym discovery system for our participation in the SemEval-2018 Task 9, which aims to discover the best (set of) candidate hypernyms for input concepts or entities, given the search space of a pre-defined vocabulary. We introduce a neural network architecture for the concerned task and empirically study various neural network models to build the representations in latent space for words and phrases. The evaluated models include convolutional neural network, long-short term memory network, gated recurrent unit and recurrent convolutional neural network. We also explore different embedding methods, including word embedding and sense embedding for better performance.  
                          </p>
                      </td>
                  </tr>
              </tbody>
          </table>
      </div>
	  
	  <div id="NHD_bib" class="blockcontent" style="DISPLAY: none">
		<pre>@InProceedings{Zhang2018Neural,
                title={{SJTU-NLP at SemEval-2018 Task 9: Neural Hypernym Discovery with Term Embeddings}},
                author={Zhang, Zhuosheng and Li, Jiangtong and Zhao, Hai and Tang, Bingjie},
                booktitle={Proceedings of the 12th International Workshop on Semantic Evaluation (SemEval-2018)},
                year={2018}, 
                pages = {903–908},
                address={New Orleans, LA, United States},
                publisher = {Association for Computational Linguistics}
            }
		  </pre>
      </div>
  
</li></ul>

<ul>
    <li>
      Pengfei Zhu, <b>Zhuosheng Zhang</b>, Jiangtong Li, Yafang Huang, Hai Zhao. <br><i> Lingke: A Fine-grained Multi-turn Chatbot for Customer Service</i>, Proceedings of the 27th International Conference on Computational Linguistics (<b>COLING 2018</b>), System Demonstrations, pp.108–112, August 20-26, 2018, Santa Fe, New Mexico, USA.
      <br>[<a href="https://arxiv.org/pdf/1808.03430.pdf">PDF</a>]
      [<a href="javascript:toggleBibtex(&#39;lingke_abstract&#39;)" target="_self">Abstract</a>]
      [<a href="javascript:toggleBibtex(&#39;lingke_bib&#39;)" target="_self">Bib</a>] 
      [<a href="http://coling2018.org/">Link</a>]
      [<a href="http://47.96.2.5:8080/ServiceBot/demo/">Demo</a>]
        <div id="lingke_abstract" class="blockcontent" style="DISPLAY: none">
            <table class="imgtable">
                <tbody>
                    <tr>
                        <td>
                                <img alt="alt text" src="./Zhuosheng Zhang, Shanghai Jiao Tong University_files/lingke.png" width="400">
                        </td>
                        <td>
                            <p style="FONT-SIZE: 16px">
                               Traditional chatbots usually need a mass of human dialogue data, especially when using supervised machine learning method. Though they can easily deal with single-turn question answering, for multi-turn the performance is usually unsatisfactory. In this paper, we present Lingke, an information retrieval augmented chatbot which is able to answer questions based on given product introduction document and deal with multi-turn conversations. We will introduce a fine-grained pipeline processing to distill responses based on unstructured documents, and attentive sequential context-response matching for multi-turn conversations.
                        </p></td>
                    </tr>
                </tbody>
            </table>
        </div>
          
          <div id="lingke_bib" class="blockcontent" style="DISPLAY: none">
            <pre>@inproceedings{zhu2018lingke,
                title = {Lingke: A Fine-grained Multi-turn Chatbot for Customer Service},
                author = {Zhu, Pengfei and Zhang, Zhuosheng and Li, Jiangtong and Huang, Yafang and Zhao, Hai},
                booktitle = {Proceedings of the 27th International Conference on Computational Linguistics (COLING 2018), System Demonstrations},
                pages = {108-–112},
                year = {2018},
            }
              </pre>
          </div>
    </li>
</ul>

<ul>
    <li>
      Zuchao Li, Shexia He, <b>Zhuosheng Zhang</b> and Hai Zhao. <br><i> Joint Learning of POS and Dependencies for Multilingual Universal Dependency Parsing</i>, <b>CoNLL 2018</b>: The SIGNLL Conference on Computational Natural Language Learning, October 31 – November 1, 2018, Brussels, Belgium.
      <br>[<a href="http://bcmi.sjtu.edu.cn/home/zhangzs/pubs/conll2018_joint.pdf">PDF</a>]
      [<a href="javascript:toggleBibtex(&#39;conll2018_joint_abstract&#39;)" target="_self">Abstract</a>]
      [<a href="javascript:toggleBibtex(&#39;conll2018_joint_bib&#39;)" target="_self">Bib</a>] 
      [<a href="http://www.conll.org/">Link</a>]
        <div id="conll2018_joint_abstract" class="blockcontent" style="DISPLAY: none">
            <table class="imgtable">
                <tbody>
                    <tr>
                        <td>
                                <img alt="alt text" src="./Zhuosheng Zhang, Shanghai Jiao Tong University_files/conll2018_joint.png" width="400">
                        </td>
                        <td>
                            <p style="FONT-SIZE: 16px">
                               This paper describes the system of team LeisureX in the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies. Our system predicts the POS tag and dependency tree jointly. For the basic tasks, including tokenization, lemmatization and morphology prediction, we employ the official baseline model (UDPipe). To train the lowresource languages, we adopt a sampling method based on other rich-resource languages. Our system achieves a macroaverage of 68.31% LAS F1 score despite of single model, with an improvement of 2.51% compared with the UDPipe.
                        </p></td>
                    </tr>
                </tbody>
            </table>
        </div>
          
          <div id="conll2018_joint_bib" class="blockcontent" style="DISPLAY: none">
            <pre>@inproceedings{Li2018joint,
                title = {Joint Learning of POS and Dependencies for Multilingual Universal Dependency Parsing},
                author = {Zuchao Li, Shexia He, Zhuosheng Zhang and Hai Zhao },
                booktitle = {CoNLL 2018: The SIGNLL Conference on Computational Natural Language Learning},
                year = {2018},
            }
              </pre>
          </div>
    </li>
</ul>

<ul>
    <li>
      <b>Zhuosheng Zhang</b>, Yuwei Wu, Zuchao Li, Shexia He, Hai Zhao. <br><i> I Know What You Want: Semantic Learning for Text Comprehension</i>, arXiv:1809.02794.
      <br>[<a href="https://arxiv.org/pdf/1809.02794.pdf">PDF</a>]
      [<a href="javascript:toggleBibtex(&#39;mrcsrl_abstract&#39;)" target="_self">Abstract</a>]
      [<a href="http://bcmi.sjtu.edu.cn/home/zhangzs/#" target="_self">Bib</a>] 
      [<a href="http://bcmi.sjtu.edu.cn/home/zhangzs/#">Link</a>]
      [<a href="http://bcmi.sjtu.edu.cn/home/zhangzs/#">Source</a>]
        <div id="mrcsrl_abstract" class="blockcontent" style="DISPLAY: none">
            <table class="imgtable">
                <tbody>
                    <tr>
                        <td>
                         <img alt="alt text" src="./Zhuosheng Zhang, Shanghai Jiao Tong University_files/mrcsrl.png" width="400">
                        </td>
                        <td>
                            <p style="FONT-SIZE: 16px">
                               Character-level representations have been broadly adopted to alleviate the problem of effectively representing rare or complex words. However, character itself is not a natural minimal linguistic unit for representation or word embedding composing due to ignoring the linguistic coherence of consecutive characters inside word. This paper presents a general subword-augmented embedding framework for learning and composing computationally-derived subword-level representations. We survey a series of unsupervised segmentation methods for subword acquisition and different subword-augmented strategies for text understanding, showing that subword-augmented embedding significantly improves our baselines in multiple text understanding tasks on both English and Chinese languages. 
                            </p>
                        </td>
                    </tr>
                </tbody>
            </table>
        </div>
    </li>
</ul>

<ul>
    <li>
      <b>Zhuosheng Zhang</b>, Shexia He, Zuchao Li, Hai Zhao. <br><i> Attentive Semantic Role Labeling with Boundary Indicator</i>, arXiv:1809.02796.
      <br>[<a href="https://arxiv.org/pdf/1809.02796.pdf">PDF</a>]
      [<a href="javascript:toggleBibtex(&#39;srl_short&#39;)" target="_self">Abstract</a>]
      [<a href="http://bcmi.sjtu.edu.cn/home/zhangzs/#" target="_self">Bib</a>] 
      [<a href="http://bcmi.sjtu.edu.cn/home/zhangzs/#">Link</a>]
      [<a href="http://bcmi.sjtu.edu.cn/home/zhangzs/#">Source</a>]
        <div id="srl_short" class="blockcontent" style="DISPLAY: none">
            <table class="imgtable">
                <tbody>
                    <tr>
					                        <td>
                         <img alt="alt text" src="./Zhuosheng Zhang, Shanghai Jiao Tong University_files/srl_short.png" width="400">
                        </td>
                        <td>
                            <p style="FONT-SIZE: 16px">
                               The goal of semantic role labeling (SRL) is to discover the predicate-argument structure of a sentence, which plays a critical role in deep processing of natural language. This paper introduces simple yet effective auxiliary tags for dependency-based SRL to enhance a syntax-agnostic model with multi-hop self-attention. Our syntax-agnostic model achieves competitive performance with state-of-the-art models on the CoNLL-2009 benchmarks both for English and Chinese. 
                            </p>
                        </td>
                    </tr>
                </tbody>
            </table>
        </div>
    </li>
</ul>



<b>[2015]</b>






<!-- 2 -->
<ul>
  <li>

  <b>Zhuosheng Zhang</b>, Haojun Ai, Jingyuan Xue, Fangfang Ma, Shengyuan Zhangyin. <br><i>Intelligent Library System Using iBeacon Firmwares</i>, Electronic Engineering &amp; Product World for Engineering Managers &amp; Desingers, 2015, (1): 16-21.
  <br>[<a href="http://bcmi.sjtu.edu.cn/home/zhangzs/pubs/iBeacon.pdf">PDF</a>]
  [<a href="javascript:toggleBibtex(&#39;iBeacon_abstract&#39;)" target="_self">Abstract</a>] 
  [<a href="javascript:toggleBibtex(&#39;iBeacon_bib&#39;)" target="_self">Bib</a>] 
  [<a href="http://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CJFQ&amp;dbname=CJFDLAST2015&amp;filename=DZCS201501015&amp;v=MDIzOTZVN3pLSVRmSWZiRzRIOVRNcm85RVlZUjhlWDFMdXhZUzdEaDFUM3FUcldNMUZyQ1VSTDJmYnVkbkZpamc=">Link</a>]
      <div id="iBeacon_abstract" class="blockcontent" style="DISPLAY: none">
          <table class="imgtable">
              <tbody>
                  <tr>
                      <td>
                              <img alt="alt text" src="./Zhuosheng Zhang, Shanghai Jiao Tong University_files/iBeacon.jpg" width="400">
                      </td>
                      <td>
                          <p style="FONT-SIZE: 16px">
                              According to technical architecture of internet of things, we designed a comprehensive solution for the intelligent library system based on the iBeacon indoor positioning technology, 3D-based real-scene,  mobile Internet,  and SaaS model, etc.  This solution supported multiple services, such as the intelligent positioning and navigation service,   reality-augmented location aware service , 3D space supervision, personalized service.
                              For the readers, they can acquire diversiform service, such as intelligent book retrieval, library navigation, message push.
                              For the librarians, they can obtain the details of readers and the operation condition of the library by the use of Unity3D to build the scene of the library.
                              The indoor location solution was designed based on the RF fingerprint of iBeacons, in which the KNN, the Inverse Distance to a Power and the IMU sensors were used.  The precision of this algorithm is better than the trilateration. As for system deployment and maintainability, our system is be superior to the positioning system based on WI-FI.
                              The opened API was provided to the third party application in the service layer of the SaaS architecture where KVP standard is used in the HTTP access requirement.
                              J2EE framework was used to provide the appropriate interface for the internet of things architecture. Multiple devices, library space information and user registration can be managed in the perception layer, data layer and application layer.
                          </p>
                      </td>
                  </tr>
              </tbody>
          </table>
      </div>
	  
	  <div id="iBeacon_bib" class="blockcontent" style="DISPLAY: none">
		<pre>		  @article{张倬胜2015,
			  title={基于iBeacon定位技术的智慧图书馆},
			  author={张倬胜 and 艾浩军 and 马方方 and 薛静远 and 章尹圣原 and 艾浩军},
			  journal={电子产品世界},
			  number={1},
			  pages={31-35},
			  year={2015},
			}
		  </pre>
      </div>
  
</li></ul>

<!-- 2 -->
<ul>
  <li>
  <b>Zhuosheng Zhang</b>, Haojun Ai, Fangfang Ma, Jingyuan Xue, Shengyuan Zhangyin. <br><i> Research on elaborate indoor positioning method based on iBeacon Firmwares</i>, Geomatics World, 2015, (2): 26-30.
  <br>[<a href="http://bcmi.sjtu.edu.cn/home/zhangzs/pubs/indoor.pdf">PDF</a>]
  [<a href="javascript:toggleBibtex(&#39;indoor_abstract&#39;)" target="_self">Abstract</a>] 
  [<a href="javascript:toggleBibtex(&#39;indoor_bib&#39;)" target="_self">Bib</a>] 
  [<a href="http://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CJFQ&amp;dbname=CJFDLAST2015&amp;filename=CHRK201502006&amp;v=MTIyNzMzcVRyV00xRnJDVVJMMmZidWRuRmlqblc3L0tKaVhaWmJHNEg5VE1yWTlGWW9SOGVYMUx1eFlTN0RoMVQ=#">Link</a>]
      <div id="indoor_abstract" class="blockcontent" style="DISPLAY: none">
          <table class="imgtable">
              <tbody>
                  <tr>
                      <td>
                              <img alt="alt text" src="./Zhuosheng Zhang, Shanghai Jiao Tong University_files/indoor.jpg" width="400">
                      </td>
                      <td>
                          <p style="FONT-SIZE: 16px">
                             Apple released iBeacon as a rough-precision position sensing distance service system, has attracted extensive attention. For more sophisticated wide-area location services, wireless fingerprinting positioning method is proposed based on iBeacon, and we give an example of location based service system of library.
                          </p>
                      </td>
                  </tr>
              </tbody>
          </table>
      </div>
	  
	   <div id="indoor_bib" class="blockcontent" style="DISPLAY: none">
		<pre>		  @article{张倬胜2015,
			  title={基于iBeacon的精细室内定位方法研究},
			  author={张倬胜 and 马方方 and 薛静远 and 艾浩军},
			  journal={地理信息世界},
			  number={02},
			  pages={26-30},
			  year={2015},
			}
		  </pre>
      </div>
  
</li></ul>
<h2 id="Shared">Shared Tasks</h2>


<h3>[2019] <i>SQuAD2.0 Leaderboard on Machine Reading Comprehension</i></h3>

<i>The leaderboard of Stanford Question Answering Dataset (<a href="https://rajpurkar.github.io/SQuAD-explorer/" target="_blank"><u>SQuAD2.0</u></a>)</i> 
<ul> 
<li>The <b>2nd best</b> in all single models and <b>3rd best</b> in all models. </li>
<li>The <b>best</b> among all academic submissions.</li>
</ul>
The official results are <a href="https://rajpurkar.github.io/SQuAD-explorer/"><span target="_blank"><u>here</u></span></a>, 
and our system report is <a href="https://rajpurkar.github.io/SQuAD-explorer/"><span><u>here</u></span></a>.

<h3>[2019] <i>RACE Leaderboard on Machine Reading Comprehension</i></h3>

<i>The leaderboard of RACE Reading Comprehension Dataset (<a href="http://www.qizhexie.com/data/RACE_leaderboard" target="_blank"><u>RACE</u></a>)</i> 
<ul> 
<li>The <b>best</b> among all submissions.</li>
<li>The <b>best</b> among all academic submissions.</li>
</ul>
The official results are <a href="http://www.qizhexie.com/data/RACE_leaderboard"><span target="_blank"><u>here</u></span></a>, 
and our system report is <a href="https://arxiv.org/pdf/1901.09381.pdf"><span><u>here</u></span></a>.

<h3>[2019] <i>SNLI Leaderboard on Language Inference</i></h3>

<i>The leaderboard of The Stanford Natural Language Inference (<a href="https://nlp.stanford.edu/projects/snli/" target="_blank"><u>SNLI</u></a>)</i> 
<ul> 
<li>The <b>best</b> among all submissions.</li>
</ul>
The official results are <a href="https://nlp.stanford.edu/projects/snli/"><span target="_blank"><u>here</u></span></a>, 
and our system report is <a href="https://arxiv.org/pdf/1809.02794.pdf"><span><u>here</u></span></a>.

<h3>[2019] <i>GLUE Leaderboard on Language Understanding</i></h3>

<i>The leaderboard of The General Language Understanding Evaluation (GLUE) benchmark (<a href="https://gluebenchmark.com/leaderboard" target="_blank"><u>GLUE</u></a>)</i> 
<ul> 
<li>The <b>3rd best</b> among all submissions.</li>
<li>The <b>best</b> among all academic submissions.</li>
</ul>

The official results are <a href="https://gluebenchmark.com/leaderboard"><span target="_blank"><u>here</u></span></a>, 
and our system report is <a href="https://gluebenchmark.com/leaderboard"><span><u>here</u></span></a>.

<h3>[2017] <i>Chinese Machine Reading Comprehension (CCL-CMRC 2017)</i></h3>

<i>The leaderboard of The 1st Evaluation Workshop on Chinese Machine Reading Comprehension Task (<a href="http://www.hfl-tek.com/cmrc2017/index.html" target="_blank"><u>CMRC</u></a>)</i> 
<ul> 
<li>The <b>best</b> Single System and the <b>Second </b> Ensemble System (Silver Medal).</li>
</ul>

The official results are <a href="http://www.hfl-tek.com/cmrc2017/index.html"><span target="_blank"><u>here</u></span></a>, 
and our system report is <a href="http://www.hfl-tek.com/cmrc2017/index.html"><span><u>here</u></span></a>.

<h2>Patents</h2>
<ul>
  <li>
  <p>A method and system for public safety monitoring based on intelligent perception of big data, Publication ID: CN 105022835. (Granted)</p>
  </li>
    <li>
  <p>An optimization for pinyin input methods on touch screen devices based on multi-factors in human-computer interaction, Application ID: CN201810102059.X. (Issued) </p>
  </li>
  <li>
  <p>A method for chemical reaction practicality judgement, Application ID: CN 201710846223.3. (Issued) </p>
  </li>
</ul>
    
<h2 id="AWARDS">Selected Awards</h2>
<ul>

<li>  <p>First Prize at 2018 IBM Watson Build Chatbot Competition</p>
</li><li>  <p>Second Prize at 2018 International E-commerce Enterpreneurship &amp; Innovation Competition</p>
</li><li>  <p>First Prize at 2018 Jiaxing E-commerce Innovation Competition</p>
</li><li>  <p>First Prize at 2017 IBM Hackathon</p>
</li><li>  <p>Best Single System Prize and the Second Ensemble System Prize (Silver Medal) in the Chinese Machine Reading Comprehension Task (CCL-CMRC 2017)</p>
</li><li>  <p>Second Prize of the semifinal in the Lenovo University Elite Challenge</p>
</li><li>  <p>First Prize in the 2015 TI Cup National Internet of Things Competition</p>
  </li><li>  <p>First Prize in the 2014 TI Cup National Internet of Things Competition</p>
  </li><li>  <p>Second Prize in the 2015 National Infomation Security Competition</p>
    </li><li>  <p>Excellent Award in IBM Innovation Mobile Application Challenge</p>
    </li><li>  <p>Third Prize of Mathematical Modeling Competition in Central China Region</p>
    </li><li>  <p>Excellent Undergraduate Thesis Award</p>
	
</li></ul>

<h2>Honors</h2>
<ul>
<li> <p> Academic Star, Shanghai Jiao Tong University (上海交通大学学术之星)</p>
</li><li>  <p>National Annual Figures Nomination of College Students, Ministry of Education of P.R.China (中国大学生年度人物提名奖)</p>
  </li><li>  <p>The CCF Elite Collegiate Award, China Computer Federation (CCF优秀大学生)</p>
</li></ul>

    <h2>Scholarships</h2>
    <ul>
        <li>  <p>National Scholarship for Graduate Student (top 2% students), YITU Tech Scholarship, Tang Lixin Scholarship, Leijun Scholarship, CSC-IBM Scholarship, Seagate Scholarship, China Telecom Scholarship </p>
    </li></ul>
    
    <h2>Academic Activities</h2>
    <ul>
        <li>  <p>Internship Research Fellowship: National Institute of Information and Communications Technology (NICT), Kyoto, Japan, 2019.6-2020.3
        </p></li><li>  <p>Teaching Assistant for "Natural language understanding (F033569)", Shanghai Jiao Tong University, Spring 2018 and Spring 2019.
        </p></li><li>  <p>Reviewer/Sub-reviewer: ACL, COLING, EMNLP, NAACL, IJCAI, AAAI, SemEval, CoNLL, PACLIC, IJCNLP, TALLIP, IVPAI, etc  
		
    </p></li></ul>
    

    <h2>Social Work</h2>
    <ul>
        <li>  <p>Data Scientist Intern at IBM (2016.6-2016.9)
        </p></li><li>  <p>President of IBM Student Tech Club in Wuhan University (2014.6-2015.6)
    </p></li></ul>

<footer style="margin-top:28px">
<div align="right">

<a title="analyze web stats" href="http://gostats.com/"><img alt="analyze web stats" src="./Zhuosheng Zhang, Shanghai Jiao Tong University_files/counter.png" style="border-width:0"></a>

<i> (Since September 19th, 2017)</i>
</div>
</footer>

 </div>
</body></html>